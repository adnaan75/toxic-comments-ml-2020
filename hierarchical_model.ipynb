{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=5, stop_words=stops, ngram_range=(1, 3), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "    tp = np.sum(np.logical_and(y_pred == 1, y == 1))\n",
    "    tn = np.sum(np.logical_and(y_pred == 0, y == 0))\n",
    "    fp = np.sum(np.logical_and(y_pred == 1, y == 0))\n",
    "    fn = np.sum(np.logical_and(y_pred == 0, y == 1))\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "y_pred = np.asarray([1, 1, 0])\n",
    "y = np.asarray([1, 0, 1])\n",
    "\n",
    "accuracy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = vectorizer.fit_transform(data.comment_text)\n",
    "ids = data.id.values\n",
    "\n",
    "y_layer_1 = data.toxic.values\n",
    "y_layer_2 = data[['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n",
    "test_split = 0.2\n",
    "dev_split = 0.1\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train_1, y_test_1, y_train_2, y_test_2, id_train, id_test = train_test_split(\n",
    "    X,\n",
    "    y_layer_1, \n",
    "    y_layer_2,\n",
    "    ids,\n",
    "    test_size = 1 - (test_split + dev_split),\n",
    "    random_state = random_state\n",
    ")\n",
    "\n",
    "X_dev, X_test, y_dev_1, y_test_1, y_dev_2, y_test_2, id_dev, id_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test_1,\n",
    "    y_test_2,\n",
    "    id_test,\n",
    "    test_size = test_split / (test_split + dev_split),\n",
    "    random_state = random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 score:  0.9342527562544483\n"
     ]
    }
   ],
   "source": [
    "from classification_utils import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "layer_1 = LogisticRegression(C=3, solver='liblinear', max_iter=10000, class_weight='balanced')\n",
    "layer_2_estimator = LogisticRegression(C=6, solver='liblinear', max_iter=10000, class_weight='balanced')\n",
    "layer_2 = MultiOutputClassifier(layer_2_estimator)\n",
    "layer_1.fit(X_train, y_train_1)\n",
    "y_pred_layer_1 = layer_1.predict(X_test)\n",
    "print(\"Layer 1 score: \", layer_1.score(X_test, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4636, 5)\n",
      "(4636, 10000)\n",
      "Layer 2 train score:  0.7758843830888698\n",
      "Layer 2 test score:  0.5421249332621463\n"
     ]
    }
   ],
   "source": [
    "print(y_train_2[y_train_1 == 1].shape)\n",
    "print(X_train[y_train_1 == 1].shape)\n",
    "\n",
    "layer_2.fit(X_train[y_train_1 == 1], y_train_2[y_train_1 == 1])\n",
    "print(\"Layer 2 train score: \", layer_2.score(X_train[y_train_1 == 1], y_train_2[y_train_1 == 1]))\n",
    "y_pred_layer_2 = layer_2.predict(X_test[y_pred_layer_1 == 1])\n",
    "print(\"Layer 2 test score: \", layer_2.score(X_test[y_pred_layer_1 == 1], y_test_2[y_pred_layer_1 == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.54%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.62      0.82      0.70      7083\n",
      " severe_toxic       0.35      0.58      0.44       761\n",
      "      obscene       0.83      0.72      0.77      3935\n",
      "       threat       0.35      0.51      0.42       222\n",
      "       insult       0.67      0.63      0.65      3718\n",
      "identity_hate       0.37      0.50      0.43       678\n",
      "\n",
      "    micro avg       0.63      0.72      0.67     16397\n",
      "    macro avg       0.53      0.63      0.57     16397\n",
      " weighted avg       0.65      0.72      0.68     16397\n",
      "  samples avg       0.07      0.07      0.06     16397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((y_pred_layer_1.shape[0], 6))\n",
    "y_pred[:, 0] = y_pred_layer_1\n",
    "y_pred[y_pred_layer_1 == 1, 1:] = y_pred_layer_2\n",
    "\n",
    "y = np.hstack((y_test_1.reshape(-1, 1), y_test_2))\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y, y_pred) * 100))\n",
    "print(classification_report(y, y_pred, target_names= ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.18%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.62      0.81      0.70      7083\n",
      " severe_toxic       0.29      0.73      0.42       761\n",
      "      obscene       0.68      0.82      0.75      3935\n",
      "       threat       0.26      0.60      0.36       222\n",
      "       insult       0.55      0.78      0.65      3718\n",
      "identity_hate       0.27      0.60      0.37       678\n",
      "\n",
      "    micro avg       0.56      0.79      0.65     16397\n",
      "    macro avg       0.44      0.72      0.54     16397\n",
      " weighted avg       0.58      0.79      0.67     16397\n",
      "  samples avg       0.06      0.07      0.06     16397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Beel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob Beel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_train = np.hstack((y_train_1.reshape(-1, 1), y_train_2))\n",
    "y_test = np.hstack((y_test_1.reshape(-1, 1), y_test_2))\n",
    "\n",
    "layer_2.fit(X_train, y_train)\n",
    "y_pred = layer_2.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(classification_report(y_test, y_pred, target_names= ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
