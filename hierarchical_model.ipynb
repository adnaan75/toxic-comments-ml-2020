{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jacob\n",
      "[nltk_data]     Beel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 400)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lemmatize(x):\n",
    "    x = word_tokenize(x)\n",
    "    x = [lemmatizer.lemmatize(i) for i in x]\n",
    "    return ' '.join(x)\n",
    "\n",
    "with open('data/dim_reduced_count_vector.pickle', 'rb') as f:\n",
    "    reduced_data = pickle.load(f)\n",
    "          \n",
    "display(reduced_data.shape)\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "# data.comment_text = data.comment_text.apply(lemmatize)\n",
    "display(data)\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=5, stop_words=stops, ngram_range=(1, 3), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "    tp = np.sum(np.logical_and(y_pred == 1, y == 1))\n",
    "    tn = np.sum(np.logical_and(y_pred == 0, y == 0))\n",
    "    fp = np.sum(np.logical_and(y_pred == 1, y == 0))\n",
    "    fn = np.sum(np.logical_and(y_pred == 0, y == 1))\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "y_pred = np.asarray([1, 1, 0])\n",
    "y = np.asarray([1, 0, 1])\n",
    "\n",
    "accuracy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0 10 ...  2  6  6]\n",
      "(159571,)\n",
      "(159571, 11)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/kmeans_assignments_tfidf.pickle', 'rb') as f:\n",
    "    clusters = pickle.load(f)\n",
    "    \n",
    "print(clusters)\n",
    "print(clusters.shape)\n",
    "\n",
    "b = np.zeros((clusters.size, clusters.max() + 1))\n",
    "b[np.arange(clusters.size), clusters] = 1\n",
    "clusters = b\n",
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "X = vectorizer.fit_transform(data.comment_text)\n",
    "# X = hstack((X, clusters))\n",
    "print(X.shape)\n",
    "ids = data.id.values\n",
    "\n",
    "y_layer_1 = data.toxic.values\n",
    "y_layer_2 = data[['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n",
    "test_split = 0.2\n",
    "dev_split = 0.1\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train_1, y_test_1, y_train_2, y_test_2, id_train, id_test = train_test_split(\n",
    "    X,\n",
    "    y_layer_1, \n",
    "    y_layer_2,\n",
    "    ids,\n",
    "    test_size = 1 - (test_split + dev_split),\n",
    "    random_state = random_state\n",
    ")\n",
    "\n",
    "X_dev, X_test, y_dev_1, y_test_1, y_dev_2, y_test_2, id_dev, id_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test_1,\n",
    "    y_test_2,\n",
    "    id_test,\n",
    "    test_size = test_split / (test_split + dev_split),\n",
    "    random_state = random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 train score:  0.9657621524513798\n",
      "Layer 1 test score:  0.9342527562544483\n"
     ]
    }
   ],
   "source": [
    "from classification_utils import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "layer_1 = LogisticRegression(C=5, solver='liblinear', max_iter=10000, class_weight='balanced')\n",
    "layer_2_estimator = LogisticRegression(C=10, solver='liblinear', max_iter=10000, class_weight='balanced')\n",
    "layer_2 = MultiOutputClassifier(layer_2_estimator)\n",
    "layer_1.fit(X_train, y_train_1)\n",
    "y_pred_layer_1 = layer_1.predict(X_test)\n",
    "print(\"Layer 1 train score: \", layer_1.score(X_train, y_train_1))\n",
    "print(\"Layer 1 test score: \", layer_1.score(X_test, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4636, 5)\n",
      "(4636, 10000)\n",
      "Layer 2 train score:  0.8237704918032787\n",
      "Layer 2 test score:  0.5278826448063855\n"
     ]
    }
   ],
   "source": [
    "print(y_train_2[y_train_1 == 1].shape)\n",
    "print(X_train[y_train_1 == 1].shape)\n",
    "\n",
    "layer_2.fit(X_train[y_train_1 == 1], y_train_2[y_train_1 == 1])\n",
    "print(\"Layer 2 train score: \", layer_2.score(X_train[y_train_1 == 1], y_train_2[y_train_1 == 1]))\n",
    "y_pred_layer_2 = layer_2.predict(X_test[y_pred_layer_1 == 1])\n",
    "print(\"Layer 2 test score: \", layer_2.score(X_test[y_pred_layer_1 == 1], y_test_2[y_pred_layer_1 == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.52%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.62      0.81      0.70      7083\n",
      " severe_toxic       0.35      0.55      0.43       761\n",
      "      obscene       0.81      0.71      0.76      3935\n",
      "       threat       0.36      0.49      0.41       222\n",
      "       insult       0.65      0.63      0.64      3718\n",
      "identity_hate       0.37      0.47      0.42       678\n",
      "\n",
      "    micro avg       0.63      0.71      0.67     16397\n",
      "    macro avg       0.53      0.61      0.56     16397\n",
      " weighted avg       0.65      0.71      0.67     16397\n",
      "  samples avg       0.07      0.07      0.06     16397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Beel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob Beel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((y_pred_layer_1.shape[0], 6))\n",
    "y_pred[:, 0] = y_pred_layer_1\n",
    "y_pred[y_pred_layer_1 == 1, 1:] = y_pred_layer_2\n",
    "\n",
    "y = np.hstack((y_test_1.reshape(-1, 1), y_test_2))\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y, y_pred) * 100))\n",
    "print(classification_report(y, y_pred, target_names= ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933884815441499\n",
      "0.8713658399022386\n",
      "Accuracy: 87.14%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.62      0.80      0.70      7083\n",
      " severe_toxic       0.29      0.71      0.42       761\n",
      "      obscene       0.68      0.81      0.74      3935\n",
      "       threat       0.27      0.56      0.37       222\n",
      "       insult       0.55      0.76      0.64      3718\n",
      "identity_hate       0.28      0.57      0.37       678\n",
      "\n",
      "    micro avg       0.56      0.78      0.65     16397\n",
      "    macro avg       0.45      0.70      0.54     16397\n",
      " weighted avg       0.58      0.78      0.66     16397\n",
      "  samples avg       0.06      0.07      0.06     16397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Beel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob Beel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_train = np.hstack((y_train_1.reshape(-1, 1), y_train_2))\n",
    "y_test = np.hstack((y_test_1.reshape(-1, 1), y_test_2))\n",
    "\n",
    "layer_2.fit(X_train, y_train)\n",
    "print(layer_2.score(X_train, y_train))\n",
    "print(layer_2.score(X_test, y_test))\n",
    "y_pred = layer_2.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(classification_report(y_test, y_pred, target_names= ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
